{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.core import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filename):\n",
    "    data = pd.read_csv(filename, sep=\"\\t\")\n",
    "    data = data[['text', 'subj']]\n",
    "    data['subj'] = data['subj'].apply(lambda subj: subj.split('\\\\'))\n",
    "    data = data.sample(n=10000)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    encoded_subjects = pd.DataFrame(mlb.fit_transform(data.pop('subj')), columns=mlb.classes_, index=data.index)\n",
    "    data = data.join(encoded_subjects)\n",
    "    return data, mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, categories = prepare_data('learn.txt')\n",
    "test, _ = prepare_data('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = pd.read_csv('subjects.txt', sep=\"\\t\", header=None, names=['code', 'desc_rus', 'description'])[['code', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.text\n",
    "X_test = test.text\n",
    "Y_train = train[categories]\n",
    "Y_test = test[categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xLengths = [len(word_tokenize(x)) for x in X_train]\n",
    "h = sorted(xLengths)  #sorted lengths\n",
    "maxLength = h[int(len(h) * 0.70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vocab_size: 51192\n"
     ]
    }
   ],
   "source": [
    "max_vocab_size = 200000\n",
    "input_tokenizer = Tokenizer(max_vocab_size)\n",
    "input_tokenizer.fit_on_texts(X_train)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "print(\"input_vocab_size:\",input_vocab_size)\n",
    "X_train = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_train), maxlen=maxLength))\n",
    "X_test = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_test), maxlen=maxLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "num_categories = len(categories)\n",
    "pool_length = 4\n",
    "lstm_output_size = 100\n",
    "batch_size = 200\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 144, 256)          13105152  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 144, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 137, 64)           131136    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                1717      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 13,304,005\n",
      "Trainable params: 13,304,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_vocab_size, embedding_dim,input_length = maxLength))\n",
    "    \n",
    "model.add(Dropout(0.8713141896816126))\n",
    "model.add(Conv1D(filters=64,kernel_size=8,\n",
    "                            padding='valid',\n",
    "                            activation='relu',\n",
    "                            strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_length))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(num_categories))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_instances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1547130ec30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0mtrain_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0mtrain_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_instances' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "            X_train, \n",
    "            Y_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=nb_epoch,\n",
    "            verbose=2,\n",
    "            validation_split=0.1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1479432078361511, 0.9536529140472412]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00211349, 0.08069116, 0.03202873, 0.01202524, 0.01524477,\n",
       "       0.05160558, 0.00356596, 0.0455012 , 0.02886715, 0.07177214,\n",
       "       0.04146872, 0.03223361, 0.011503  , 0.26273057, 0.01791821,\n",
       "       0.00116026, 0.11917093], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(predicted):\n",
    "    for j, prob in enumerate(row):\n",
    "        if prob >= 0.5:\n",
    "            predicted[i][j]=1\n",
    "        else:\n",
    "            predicted[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          00       0.00      0.00      0.00        78\n",
      "          e1       0.36      0.77      0.49       986\n",
      "          e2       0.00      0.00      0.00       181\n",
      "          e3       0.70      0.87      0.77      1465\n",
      "          e4       0.14      0.45      0.21       308\n",
      "          e5       0.00      0.00      0.00       343\n",
      "          e7       0.00      0.00      0.00         5\n",
      "          e8       0.13      0.81      0.23       302\n",
      "          e9       0.00      0.00      0.00       212\n",
      "          f1       0.00      0.00      0.00       374\n",
      "          f2       0.00      0.00      0.00       199\n",
      "          f3       0.24      0.16      0.19       616\n",
      "          f4       0.00      0.00      0.00       116\n",
      "          f5       0.56      0.79      0.66      2052\n",
      "          f7       0.86      0.79      0.83      3866\n",
      "          f8       0.00      0.00      0.00        40\n",
      "          f9       0.00      0.00      0.00       573\n",
      "\n",
      "   micro avg       0.53      0.61      0.57     11716\n",
      "   macro avg       0.18      0.27      0.20     11716\n",
      "weighted avg       0.52      0.61      0.55     11716\n",
      " samples avg       0.57      0.65      0.58     11716\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anna/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.array(Y_test), predicted, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5206369450960237, 0.6149709798566063, 0.5473430430050416, None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(np.array(Y_test), predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Macro-F1-Score: 0.20928447141731724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('sklearn Macro-F1-Score:', f1_score(np.array(Y_train), np.array(Y_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
